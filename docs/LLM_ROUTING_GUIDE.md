# ğŸš¦ LLM Routing - Guia Completo

**Data:** 2025-01-XX  
**Status:** âœ… IMPLEMENTADO E TESTADO

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura](#arquitetura)
3. [Providers LLM](#providers-llm)
4. [Providers Embeddings](#providers-embeddings)
5. [Circuit Breaker](#circuit-breaker)
6. [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
7. [Custos](#custos)
8. [Monitoramento](#monitoramento)
9. [Testes](#testes)

---

## ğŸ“Œ VisÃ£o Geral

O sistema de **LLM Routing** implementa fallback automÃ¡tico entre mÃºltiplos provedores de IA, garantindo alta disponibilidade e resiliÃªncia.

### BenefÃ­cios

âœ… **Alta Disponibilidade**: Se um provider falhar, usa automaticamente o prÃ³ximo  
âœ… **Retry Logic**: Tenta novamente antes de fazer fallback  
âœ… **Circuit Breaker**: Evita chamadas repetidas a serviÃ§os falhando  
âœ… **Custo-BenefÃ­cio**: Usa provider mais barato como fallback  
âœ… **Zero Config**: Funciona em modo mock sem API keys

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AplicaÃ§Ã£o      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Router (src/lib/llm-router.ts)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º 1ï¸âƒ£ GPT-4o-mini (OpenAI) â”€â”€â–º âœ… Sucesso
       â”‚
       â”œâ”€â”€â–º âŒ Falha â†’ Retry (2x)
       â”‚
       â”œâ”€â”€â–º âŒ Falha â†’ Circuit Breaker
       â”‚
       â””â”€â”€â–º 2ï¸âƒ£ LLaMA 3.1 8B (Groq) â”€â”€â–º âœ… Fallback
            â”‚
            â””â”€â”€â–º âŒ Todos falharam â†’ Mock Mode
```

### Fluxo de DecisÃ£o

1. **Verificar Circuit Breaker**: Provider estÃ¡ saudÃ¡vel?
2. **Tentar Provider PrimÃ¡rio**: GPT-4o-mini (2 retries)
3. **Se falhar**: Registrar falha no Circuit Breaker
4. **Fallback**: Tentar LLaMA 3.1 8B Instant (2 retries)
5. **Ãšltimo Recurso**: Mock Mode (desenvolvimento)

---

## ğŸ¤– Providers LLM

### 1ï¸âƒ£ PrimÃ¡rio: GPT-4o-mini (OpenAI)

```typescript
{
  name: 'openai',
  model: 'gpt-4o-mini',
  priority: 1,
  costPer1MTokens: { input: 0.15, output: 0.6 }
}
```

**Vantagens:**
- Qualidade superior
- Multimodal (texto + imagens)
- Function calling robusto
- PortuguÃªs excelente

**Custos:**
- Input: $0.15/1M tokens
- Output: $0.60/1M tokens

**Quando usar:**
- ConversaÃ§Ã£o com clientes
- ClassificaÃ§Ã£o de intenÃ§Ãµes
- GeraÃ§Ã£o de textos de vendas

### 2ï¸âƒ£ Fallback: LLaMA 3.1 8B Instant (Groq)

```typescript
{
  name: 'groq',
  model: 'llama-3.1-8b-instant',
  priority: 2,
  costPer1MTokens: { input: 0.05, output: 0.08 }
}
```

**Vantagens:**
- Extremamente rÃ¡pido (300+ tokens/s)
- Muito barato (75% mais barato)
- Tier gratuito generoso
- Open source

**Custos:**
- Input: $0.05/1M tokens
- Output: $0.08/1M tokens

**Tier Gratuito:**
- 30 requisiÃ§Ãµes/minuto
- 14.4k tokens/minuto

---

## ğŸ§  Providers Embeddings

### 1ï¸âƒ£ PrimÃ¡rio: text-embedding-3-small (OpenAI)

```typescript
{
  name: 'openai',
  model: 'text-embedding-3-small',
  dimensions: 1536,
  priority: 1,
  costPer1MTokens: 0.02
}
```

**Vantagens:**
- MTEB Score: 62.3 (excelente)
- PortuguÃªs de alta qualidade
- LatÃªncia: 50-100ms
- IntegraÃ§Ã£o simples

**Custos:**
- $0.02/1M tokens
- ~$0.60/mÃªs (10k queries/dia)

### 2ï¸âƒ£ Fallback: embed-multilingual-v3.0 (Cohere)

```typescript
{
  name: 'cohere',
  model: 'embed-multilingual-v3.0',
  dimensions: 1024, // normalizado para 1536
  priority: 2,
  costPer1MTokens: 0.01
}
```

**Vantagens:**
- Especializado em multilingual (100+ idiomas)
- Excelente em portuguÃªs
- 50% mais barato que OpenAI
- Tier gratuito: 100 chamadas/minuto

**Custos:**
- $0.01/1M tokens
- ~$0.30/mÃªs (10k queries/dia)

**NormalizaÃ§Ã£o:**
- Cohere: 1024 dimensÃµes â†’ padding para 1536
- MantÃ©m compatibilidade com banco de dados

---

## âš¡ Circuit Breaker

### Como Funciona

```typescript
class CircuitBreaker {
  threshold: 3,      // Falhas antes de abrir circuito
  timeout: 60000,    // 1 minuto para tentar novamente
}
```

### Estados

1. **CLOSED** (Normal)
   - Provider funcionando
   - RequisiÃ§Ãµes passam normalmente

2. **OPEN** (Bloqueado)
   - 3+ falhas consecutivas
   - Bloqueia requisiÃ§Ãµes por 1 minuto
   - Fallback automÃ¡tico para prÃ³ximo provider

3. **HALF-OPEN** (Teste)
   - ApÃ³s timeout, permite 1 requisiÃ§Ã£o teste
   - Se sucesso â†’ CLOSED
   - Se falha â†’ OPEN novamente

### BenefÃ­cios

âœ… Evita cascade failures  
âœ… Reduz latÃªncia (nÃ£o tenta providers falhando)  
âœ… Auto-recuperaÃ§Ã£o apÃ³s timeout  
âœ… Logs detalhados para debugging

---

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# .env
OPENAI_API_KEY="sk-..."      # PrimÃ¡rio (LLM + Embeddings)
GROQ_API_KEY="gsk-..."       # Fallback (LLM)
COHERE_API_KEY="..."         # Fallback (Embeddings)
```

### Obter API Keys

#### OpenAI
1. https://platform.openai.com/api-keys
2. Criar novo projeto
3. Gerar API key
4. Adicionar crÃ©ditos ($5 mÃ­nimo)

#### Groq
1. https://console.groq.com/keys
2. Login com Google/GitHub
3. Criar API key
4. Tier gratuito ativo automaticamente

#### Cohere
1. https://dashboard.cohere.com/api-keys
2. Criar conta
3. Gerar trial key (gratuita)
4. 100 req/min sem cobranÃ§as

### Modo Mock (Desenvolvimento)

Se nenhuma API key configurada:
```typescript
// Automaticamente ativa mock mode
const response = await chatCompletion(messages);
// Retorna respostas prÃ©-programadas
```

---

## ğŸ’° AnÃ¡lise de Custos

### LLM Costs (10k mensagens/mÃªs)

| Provider | Input/Output | Custo Mensal | Economia |
|----------|--------------|--------------|----------|
| GPT-4o-mini | $0.15/$0.60 | ~$15/mÃªs | - |
| LLaMA 3.1 8B | $0.05/$0.08 | ~$2.60/mÃªs | 83% |

**EstratÃ©gia:**
- Usar GPT-4o-mini para precisÃ£o
- Fallback Groq economiza $12.40/mÃªs se OpenAI falhar 100%

### Embeddings Costs (300k queries/mÃªs)

| Provider | Custo/1M | Custo Mensal | Economia |
|----------|----------|--------------|----------|
| OpenAI | $0.02 | ~$6/mÃªs | - |
| Cohere | $0.01 | ~$3/mÃªs | 50% |

**EstratÃ©gia:**
- OpenAI primÃ¡rio (melhor qualidade)
- Cohere fallback economiza $3/mÃªs

### Total Estimado

```
CenÃ¡rio Normal (95% OpenAI):
- LLM: $14.25/mÃªs
- Embeddings: $5.70/mÃªs
- TOTAL: ~$20/mÃªs

CenÃ¡rio Fallback (50/50):
- LLM: $8.80/mÃªs
- Embeddings: $4.50/mÃªs
- TOTAL: ~$13.30/mÃªs (34% economia)
```

---

## ğŸ“Š Monitoramento

### Logs Estruturados

```typescript
logger.info({
  provider: 'openai',
  model: 'gpt-4o-mini',
  attempt: 1,
  maxRetries: 2,
  usage: { prompt_tokens: 50, completion_tokens: 20 }
}, 'LLM call successful');
```

### MÃ©tricas Importantes

1. **Success Rate**: `successes / total_attempts`
2. **Fallback Rate**: `fallbacks / total_attempts`
3. **Circuit Breaker Opens**: Quantas vezes abriu
4. **Average Latency**: Por provider
5. **Cost per Request**: Token usage

### API de Status

```typescript
import { getLLMProvidersStatus } from './lib/llm-router';

const status = getLLMProvidersStatus();
// [
//   { name: 'openai', enabled: true, circuitBreakerOpen: false },
//   { name: 'groq', enabled: true, circuitBreakerOpen: false }
// ]
```

---

## ğŸ§ª Testes

### Executar Testes

```bash
# Todos os testes de routing
npm test tests/unit/llm-router.test.ts
npm test tests/unit/embedding-router.test.ts

# Com coverage
npm run test:coverage

# Watch mode
npm run test:watch
```

### CenÃ¡rios Testados

âœ… GeraÃ§Ã£o de resposta vÃ¡lida  
âœ… ClassificaÃ§Ã£o de intenÃ§Ãµes  
âœ… Respeito a maxTokens  
âœ… Status dos providers  
âœ… Circuit breaker reset  
âœ… Fallback quando provider falha  
âœ… Mock mode sem API keys  

âœ… Embeddings com dimensÃµes corretas  
âœ… NormalizaÃ§Ã£o de vetores  
âœ… RejeiÃ§Ã£o de texto vazio  
âœ… Batch processing  
âœ… Similaridade de cosseno  
âœ… Performance < 5s  

### Exemplo de Teste

```typescript
it('deve usar fallback quando primÃ¡rio falha', async () => {
  // Simular falha do OpenAI
  process.env.OPENAI_API_KEY = '';
  
  const messages = [
    { role: 'user', content: 'OlÃ¡' }
  ];
  
  const response = await chatCompletion(messages);
  
  expect(response).toBeTruthy();
  // Deve ter usado Groq ou Mock
});
```

---

## ğŸ”§ Troubleshooting

### Problema: "All providers failed"

**Causa:** Todas as API keys invÃ¡lidas ou sem crÃ©ditos

**SoluÃ§Ã£o:**
1. Verificar `process.env.OPENAI_API_KEY`
2. Verificar `process.env.GROQ_API_KEY`
3. Verificar saldo nas contas
4. Em dev, funciona em mock mode

### Problema: Circuit breaker sempre aberto

**Causa:** Provider com problemas contÃ­nuos

**SoluÃ§Ã£o:**
```typescript
import { resetCircuitBreaker } from './lib/llm-router';
resetCircuitBreaker(); // ForÃ§ar reset
```

### Problema: Embeddings com dimensÃµes erradas

**Causa:** Cohere retorna 1024 dim

**SoluÃ§Ã£o:** JÃ¡ normalizado automaticamente para 1536

---

## ğŸ“š ReferÃªncias

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Groq API Docs](https://console.groq.com/docs)
- [Cohere Embeddings](https://docs.cohere.com/docs/embeddings)
- [Circuit Breaker Pattern](https://martinfowler.com/bliki/CircuitBreaker.html)

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [x] LLM Router criado
- [x] Embedding Router criado
- [x] Circuit Breaker implementado
- [x] Retry logic adicionado
- [x] Cohere SDK integrado
- [x] groq.ts atualizado
- [x] embeddings.ts atualizado
- [x] env.ts atualizado
- [x] .env.example documentado
- [x] Testes unitÃ¡rios criados
- [x] DocumentaÃ§Ã£o completa

---

## ğŸ¯ PrÃ³ximos Passos

1. **Gerar embeddings Cohere** para comparaÃ§Ã£o
2. **Benchmark providers** (latÃªncia, qualidade)
3. **Dashboard de monitoramento** (Grafana)
4. **Alertas** quando circuit breaker abre
5. **Cache de embeddings** (Redis)

---

**Ãšltima atualizaÃ§Ã£o:** 2025-01-XX  
**VersÃ£o:** 2.0  
**Status:** âœ… PRODUÃ‡ÃƒO
